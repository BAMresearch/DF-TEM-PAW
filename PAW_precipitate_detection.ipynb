{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d41620a",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected as thomas.hanke\n",
      "User ID: 102\n",
      "User Full Name: Thomas Hanke\n",
      "Your Groups:\n",
      "   Name: matolab  ID: 53\n",
      "   Name: kupferdigital  ID: 54\n",
      "Current group:  matolab\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from scipy import ndimage\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "from omero_tools import OmeroConnect\n",
    "from matolab_tools import annotate_csv_upload, annotate_csv_uri, csvw_to_rdf, get_joined_rdf, create_mapping\n",
    "# need credentials\n",
    "username = input(\"Username: \")\n",
    "password = getpass(\"OMERO Password: \")\n",
    "\n",
    "HOST = 'wss://wss.omero.matolab.org'\n",
    "omero_conn=OmeroConnect(HOST,username,password)\n",
    "\n",
    "def run_detection(\n",
    "        image,\n",
    "        threshold_method: str = \"Otsu\",\n",
    "        size_thresh: float = 80,\n",
    "        dilate_kernel_size: int = 3,\n",
    "        median_filter_radius: int = 4,\n",
    "        plot=False\n",
    "):\n",
    "\n",
    "    name = image.name\n",
    "    print(\"Image Name: \"+name)\n",
    "\n",
    "    gray = omero_conn.get_grayscale(image.id)\n",
    "\n",
    "    print(\"Grayscale image shape:\", gray.shape)\n",
    "    print(\"Grayscale image data type:\", gray.dtype)\n",
    "\n",
    "    # Apply median filter using OpenCV\n",
    "\n",
    "    #selem = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*median_filter_radius + 1, 2*median_filter_radius+1))\n",
    "    filtered = cv2.medianBlur(gray, 2 * median_filter_radius + 1)\n",
    "\n",
    "    # Display the original and filtered images side by side\n",
    "    if plot:\n",
    "        fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax0.imshow(gray, cmap='gray')\n",
    "        ax0.set_title('Step1: Load Original Image')\n",
    "        ax0.axis('off')\n",
    "        ax1.imshow(filtered, cmap='gray')\n",
    "        ax1.set_title('Step2: Median Blur Filter')\n",
    "        ax1.axis('off')\n",
    "\n",
    "    # Apply Otsu's thresholding using OpenCV\n",
    "    if threshold_method == \"Otsu\":\n",
    "        ret, thresh = cv2.threshold(\n",
    "            filtered, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        print('Threshold value is {}'.format(ret))\n",
    "    else:\n",
    "        print(\"only Otsu thresholding supported, skippping thresholding\")\n",
    "        thresh = gray\n",
    "\n",
    "    # Dilate the thresholded image using a 3x3 kernel\n",
    "    kernel = np.ones((dilate_kernel_size, dilate_kernel_size), np.uint8)\n",
    "    dilated = cv2.dilate(thresh, kernel)\n",
    "\n",
    "    if plot:\n",
    "        fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax0.imshow(thresh, cmap='gray')\n",
    "        ax0.set_title('Step3: Otsu Threshold')\n",
    "        ax0.axis('off')\n",
    "        ax1.imshow(dilated, cmap='gray')\n",
    "        ax1.set_title('Step4: Dilated Image')\n",
    "        ax1.axis('off')\n",
    "\n",
    "    # Remove small objects using OpenCV's morphologyEx function\n",
    "    morphed = cv2.morphologyEx(dilated, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < size_thresh:\n",
    "            cv2.drawContours(morphed, [cnt], 0, 0, -1)\n",
    "\n",
    "    # delete all previously defined shapes\n",
    "    omero_conn.delete_rois(image.id)\n",
    "\n",
    "    # upload shapes to omero\n",
    "    omero_conn.create_omero_roi_polygons(image.id, contours)\n",
    "\n",
    "    # Apply clear border to the dilated image\n",
    "    mask = morphed == 255\n",
    "    mask = clear_border(mask)\n",
    "\n",
    "    # Label the mask and count the number of precipitates detected\n",
    "    s = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
    "    labeled_mask, num_labels = ndimage.label(mask, structure=s)\n",
    "    img2 = label2rgb(labeled_mask, bg_label=0)\n",
    "\n",
    "    # Display the labeled mask\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.imshow(img2)\n",
    "        ax.set_title('Step5: Contour Finding')\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "        print(f\"Number of precipitates detected: {num_labels}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "634f3b1f",
   "metadata": {},
   "source": [
    "## The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc57a6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190C_1000h\n",
      "---- Loaded image ID: 83\n",
      "---- Loaded image ID: 84\n",
      "---- Loaded image ID: 85\n",
      "---- Loaded image ID: 74\n",
      "---- Loaded image ID: 75\n",
      "---- Loaded image ID: 76\n",
      "---- Loaded image ID: 77\n",
      "---- Loaded image ID: 78\n",
      "---- Loaded image ID: 79\n",
      "---- Loaded image ID: 80\n",
      "---- Loaded image ID: 81\n",
      "---- Loaded image ID: 82\n",
      "Dataset ID: 53\n",
      "Dataset Name: 190C_1000h\n",
      "Image Name: 190C-1000h_Sample1_Stelle 10 DF 30s.dm3\n",
      "Grayscale image shape: (2048, 2048)\n",
      "Grayscale image data type: uint8\n",
      "Threshold value is 61.0\n",
      "deleted rois: [542]\n",
      "added 33 polygon shapes to image\n"
     ]
    }
   ],
   "source": [
    "#load all images from selected datasets, run detection algorithm and upload found contours as polygons in a omero roi\n",
    "#results are saved as detection_runs.csv\n",
    "datasets=omero_conn.get_datasets(51)\n",
    "data=list()\n",
    "for dataset in datasets:\n",
    "    print(dataset.name)\n",
    "    images = omero_conn.get_images(dataset.id)\n",
    "    for image in images:\n",
    "        startTime = datetime.now().isoformat()\n",
    "        info = image.name.split(\".\",1)[0].split('_')\n",
    "        state=info[0].split(\"-\")\n",
    "        if len(state)>1:\n",
    "            anneal_temp, anneal_time = info[0].split(\"-\")\n",
    "            anneal_temp = float(anneal_temp.rsplit('C',1)[0])\n",
    "            anneal_time = float(anneal_time.rsplit('h',1)[0])\n",
    "        else:\n",
    "            anneal_temp, anneal_time = 23.0, 0.0\n",
    "        specimen = info[1].split('Sample',1)[-1]\n",
    "        pos = info[2].split('Sample',1)[-1]\n",
    "        threshold_method=\"Otsu\"\n",
    "        size_thresh=80\n",
    "        dilate_kernel_size=3\n",
    "        median_filter_radius=4\n",
    "        info_dict={\n",
    "            \"SpecimenName\": dataset.name+'_'+specimen,\n",
    "            \"Aging Temp [Â°C]\": float(anneal_temp),\n",
    "            \"Aging Time [h]\": float(anneal_time),\n",
    "            \"Creep Stress [MPa]\": 0,\n",
    "            \"Dataset\": meta_extractor_api+\"dataset/\"+str(dataset.id),\n",
    "            \"Position_Id\": pos,\n",
    "            \"Image\": meta_extractor_api+\"image/\"+str(image.id),\n",
    "            \"ROIs\": meta_extractor_api+\"rois/\"+str(image.id),\n",
    "            \"DiskRadiusValue [px]\": median_filter_radius,\n",
    "            \"Threshold Method\": threshold_method,\n",
    "            \"Dilation Kernel Size [px]\": dilate_kernel_size,\n",
    "            \"Date\": startTime\n",
    "        }\n",
    "        run_detection(image,threshold_method=\"Otsu\",size_thresh=80,dilate_kernel_size=3,median_filter_radius=4)\n",
    "        data.append(info_dict)\n",
    "        #break\n",
    "    #break\n",
    "df=pd.DataFrame(data)\n",
    "df.to_csv('detection_runs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b226c24",
   "metadata": {},
   "source": [
    "# Processing Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfe3ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvw annotation file created, suggested name: detection_runs-metadata.json\n",
      "wrote csvw meta data to detection_runs-metadata.json\n"
     ]
    }
   ],
   "source": [
    "# annotate detection_runs.csv\n",
    "response=annotate_csv_uri(\"https://github.com/BAMresearch/DF-TEM-PAW/raw/main/detection_runs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db349af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writen serialized table to detection_runs.ttl\n"
     ]
    }
   ],
   "source": [
    "# serialize table to rdf, uses already commited files on main branch\n",
    "meta_url=\"https://github.com/BAMresearch/DF-TEM-PAW/raw/main/detection_runs-metadata.json\"\n",
    "response=csvw_to_rdf(meta_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb82cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writen mapping file to detection_runs-map.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a rule bases mapping between the data in detection_runs and the precipitate analysis knowledge graph \n",
    "meta_url=\"https://github.com/BAMresearch/DF-TEM-PAW/raw/main/detection_runs-metadata.json\"\n",
    "method_url=\"https://github.com/BAMresearch/DF-TEM-PAW/raw/main/PrecipitateAnalysisWorkflow.ttl\"\n",
    "d_classes= [\n",
    "    \"http://www.w3.org/ns/oa#Annotation\",''\n",
    "    \"http://www.w3.org/ns/csvw#Column\"\n",
    "]\n",
    "m_classes=[\"https://w3id.org/pmd/co/ValueObject\",]\n",
    "pred=\"https://w3id.org/pmd/co/isResourceOf\"\n",
    "map_dict={\n",
    "    \"diskRadius\": \"table-1-DiskradiusvaluePx\",\n",
    "    \"kernelSize\": \"table-1-DilationKernelSizePx\",\n",
    "    \"thresholdMethod\": \"table-1-ThresholdMethod\",\n",
    "    \"specimenAgingTemperature\": \"table-1-AgingTempC\",\n",
    "    \"specimenCreepStress\": \"table-1-CreepStressMpa\",\n",
    "    \"investigationPosition\": \"table-1-Position_Id\",\n",
    "    \"specimenName\": \"table-1-Specimenname\",\n",
    "    \"specimenAgingTime\": \"table-1-AgingTimeH\",\n",
    "    \"darkfieldTransmissionElectronMicroscopeImage\": \"table-1-Image\",\n",
    "    \"precipitateRegion\": \"table-1-Rois\",\n",
    "    \"executionDate\": \"table-1-Date\",\n",
    "}\n",
    "create_mapping(meta_url=meta_url,method_url=method_url,data_super_classes=d_classes,predicate=pred,method_super_classes=m_classes,map_dict=map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46d6bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied 10 mapping rules and skipped 0\n",
      "wrote joint graph to detection_runs-joined.ttl\n"
     ]
    }
   ],
   "source": [
    "# join all data and replicate template knowledge graph for every row in table\n",
    "mapping_url = \"https://github.com/BAMresearch/DF-TEM-PAW/raw/main/detection_runs-map.yaml\"\n",
    "data_url = \"https://github.com/BAMresearch/DF-TEM-PAW/raw/main/detection_runs.ttl\"\n",
    "duplicate_for_table = True\n",
    "get_joined_rdf(map_url=mapping_url,data_url=data_url,duplicate_for_table=duplicate_for_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07988932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_skimage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "62618c75dbbeddb9025e5d06afcb46d4db33ffb9a9c357e8bdf42838eaa81943"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
